# SocialMediaStatCollector

I wrote this program for a research project conducted by researchers at University of Iowa. They wanted to find how scientific/medical journal articles on the internet are communicated on popular Social Media websites such as FaceBook and Twitter. My program attempts to accomplish the first part of the research that was to collect Social Media statistics such as number of shares, likes, comments on each article.

The researchers identified PubMed (http://www.ncbi.nlm.nih.gov/pubmed) as a good resource to collect statistics on given that there was prior similar research done on this topic (link-here). In this script, I make the use of Facebook/Twitter/Linkedin web APIs to retrieve social media statistics about a given article. But, there is a drawback in using these web APIs because we need to send an HTTP request to get a response and when you need a lot of requests to send, probably in millions, which can overload the server and possibly cause it crash or slow down considerably. Hence, these Facebook/Twitter/Linkedin web APIs have implemented a concept of call rate limitation which blocks incoming requests from an IP address if the number of requests per given time exceed a given threshold. 

Such limitation seems reasonable to avoid issues such as DDoS attacks, fair treatment towards each request but slows down our task considerably. For example, if we are to collect statistics of all published PubMed articles in year 2015, the website will loosely return about a million articles. For each, we will extract related/relevent links that point to more detailed sources at sister websites, let the average number of these links be 3 and we are collecting stats for 3 social networks sites, Hence, we will need to make (1,000,000 * 3 * 3 = 9,000,000) HTTP requests to get all the data. Given, the call rate of Facebook 1 per second, it will take us approximately 41 days to collect data in a serial threaded program that accounts for the rate limit.

To speed up the process, we could have multiple computers/hosts running the same program in parallel but this solution seems expensive to implement. Instead, we can have multiple threads in the same program running parallel, but the fundamental issue still remains, all the HTTP requests will be sent from the same IP address and will get our program blocked. As a workaround, we can send our HTTP requests through a proxy server 

